{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a4a834",
   "metadata": {},
   "source": [
    "### This is Natural Language Processing Project in which Natural Language Toolkit is used and base on Extraction Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42cdced",
   "metadata": {},
   "source": [
    "## Preparing the data. Here data is scraping from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50b24301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4 as BeautifulSoup  #use to fetcha the articles text\n",
    "import urllib.request        #use for connectiong to the page and retrieving the HTML\n",
    "import re\n",
    "# Fetching the content from the URL\n",
    "fetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Brahma_Kumaris')\n",
    "\n",
    "article_read = fetched_data.read()\n",
    "\n",
    "# Parsing the URL content and storing in a variable\n",
    "article_parsed = BeautifulSoup.BeautifulSoup(article_read,'lxml')\n",
    "\n",
    "# Returning <p> tags\n",
    "paragraphs = article_parsed.find_all('p')\n",
    "\n",
    "article_content = ''\n",
    "\n",
    "# Looping through the paragraphs and adding them to the variable\n",
    "for p in paragraphs:  \n",
    "    article_content += p.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90198c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aad37a0",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9092eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    # Reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    # Creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4de1c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17067"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_article_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e68fcbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table=_create_dictionary_table(formatted_article_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011c64a",
   "metadata": {},
   "source": [
    "## Tokenizing the article into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05834d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sentences = sent_tokenize(article_content)\n",
    "(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee475cea",
   "metadata": {},
   "source": [
    "## Finding the weighted frequencies of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9897ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    # Algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] /        sentence_wordcount_without_stop_words\n",
    "      \n",
    "    return sentence_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c89d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores=_calculate_sentence_scores(sentences, frequency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba544a4",
   "metadata": {},
   "source": [
    "## Calculating the threshold of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80674654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    # Calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    # Getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "848ab3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.152466325906582"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = _calculate_average_score(sentence_scores)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50f5793",
   "metadata": {},
   "source": [
    "## Function to generate a summary from article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6769561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f307a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " He reported what he said were a series of visions and other transcendental experiences that commenced around 1935 and became the basis for the discourses. He reported the rewriting of the revelatory messages (Murlis) by the Brahma Kumari.\n"
     ]
    }
   ],
   "source": [
    "#producing the summary\n",
    "summary_results = _get_article_summary(sentences, sentence_scores, 1.95* threshold)\n",
    "print(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7705a07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e33c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
